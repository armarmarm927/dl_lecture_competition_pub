{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMZKDO2oB/sevzobHuGxVrt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/armarmarm927/dl_lecture_competition_pub/blob/main/sparkproto16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "FkHz9vLQhqwu"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.models as models\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzXRnH-epPZN",
        "outputId": "c222d18b-4769-47fe-db8c-a2a19a5372f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "7WYmYra3p2qu"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomAffine([-10,10],scale=(1,1.25)),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "    transforms.RandomErasing(p=0.5,scale=(0.02,0.33),ratio=(0.3,3.3),value=0,inplace=False)\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])"
      ],
      "metadata": {
        "id": "aVF0lLtFp7_s"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4)\n",
        "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=4)"
      ],
      "metadata": {
        "id": "q__F-HPkp8ue"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft = models.resnet50(pretrained=True)\n",
        "model_ft.fc = nn.Linear(model_ft.fc.in_features, 10)\n",
        "net = model_ft.to(device)"
      ],
      "metadata": {
        "id": "sG0BhaCMp_pT"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)"
      ],
      "metadata": {
        "id": "T4sh7RDfqC1Q"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 50\n",
        "loss_list = []\n",
        "acc_list = []\n",
        "train_acc_list = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    net.train()\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct_train += (predicted == labels).sum().item()\n",
        "        total_train += labels.size(0)\n",
        "\n",
        "    train_accuracy = 100. * correct_train / total_train\n",
        "    train_acc_list.append(train_accuracy)\n",
        "    print(f'Epoch {epoch+1}: Loss: {epoch_loss/len(train_loader):.4f}, Train Accuracy: {train_accuracy:.2f}%')\n",
        "    loss_list.append(epoch_loss/len(train_loader))\n",
        "\n",
        "    net.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = net(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "            y_true.extend(labels.cpu().numpy())\n",
        "            y_pred.extend(predicted.cpu().numpy())\n",
        "\n",
        "    test_accuracy = 100. * correct / total\n",
        "    acc_list.append(test_accuracy)\n",
        "    print(f'Test Accuracy: {test_accuracy:.2f}%')\n",
        "\n",
        "    # 混同行列の出力\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    print(f'Confusion Matrix (Epoch {epoch+1}):')\n",
        "    print(cm)\n",
        "\n",
        "    torch.save(net.state_dict(), '/content/drive/MyDrive/Weight_Epoch50.pth')\n",
        "    scheduler.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rrOaC6KuqFEM",
        "outputId": "7f1d665e-ec71-405d-d37b-c5dca91fd9bf"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Loss: 1.1597, Train Accuracy: 60.15%\n",
            "Test Accuracy: 72.86%\n",
            "Confusion Matrix (Epoch 1):\n",
            "[[845  19  23  14  13   6   6   2  60  12]\n",
            " [ 21 875   0   4   0  14   6   0  15  65]\n",
            " [104   7 536  28 110 126  66   9  10   4]\n",
            " [ 31  10  39 394  74 379  41  14   6  12]\n",
            " [ 41   3  25  20 809  57  22  20   3   0]\n",
            " [ 17   2  26  58  59 804   9  21   2   2]\n",
            " [  7   6  33  48  60  57 783   1   4   1]\n",
            " [ 61   2  15  19 140 134   9 606   2  12]\n",
            " [ 66  37   7  15   9   6   7   3 845   5]\n",
            " [ 64  77   3  10   1  15   5   4  32 789]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Loss: 0.9996, Train Accuracy: 65.80%\n",
            "Test Accuracy: 68.13%\n",
            "Confusion Matrix (Epoch 2):\n",
            "[[636  43  83  10   9   1   8   1 157  52]\n",
            " [ 17 906   4   4   0   6   5   0  22  36]\n",
            " [ 64  15 717  48  31  43  51   8  17   6]\n",
            " [ 41  17 116 585  22 112  59  15  27   6]\n",
            " [ 23   6 155 109 538  27  92  26  22   2]\n",
            " [ 22   9 126 189  26 585  17  13  12   1]\n",
            " [  9  21  80  81   7  10 783   2   7   0]\n",
            " [ 32   7  85 110  67  62  20 596   7  14]\n",
            " [ 39  72   6   7   5   4   4   1 847  15]\n",
            " [ 24 273   9  14   1  10  10   5  34 620]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: Loss: 0.9521, Train Accuracy: 67.66%\n",
            "Test Accuracy: 76.70%\n",
            "Confusion Matrix (Epoch 3):\n",
            "[[771  32  42   6  11   2   4  10  96  26]\n",
            " [  6 885   5   1   0   4   3   1  30  65]\n",
            " [ 66   4 695  26  88  30  34  29  17  11]\n",
            " [ 17   5  98 561  56 150  42  32  24  15]\n",
            " [ 17   3  52  37 771  40  29  39  12   0]\n",
            " [  8   2  85 138  37 661  18  47   4   0]\n",
            " [  3   3  48  54  22  21 832   6   8   3]\n",
            " [ 21   5  32  36  41  39   2 807   4  13]\n",
            " [ 46  28  10   9   2   5   5   2 885   8]\n",
            " [ 26  90   6   9   1   6   2   8  50 802]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: Loss: 0.7616, Train Accuracy: 73.79%\n",
            "Test Accuracy: 78.83%\n",
            "Confusion Matrix (Epoch 4):\n",
            "[[857  13  25  15   7   0   3   4  62  14]\n",
            " [ 17 920   7   1   0   3   0   1  25  26]\n",
            " [ 84   3 727  46  62  39  22  13   3   1]\n",
            " [ 23  12  52 701  53  98  28  17  11   5]\n",
            " [ 20   3  55  44 807  21  10  29   7   4]\n",
            " [ 15   5  38 180  38 680   9  32   3   0]\n",
            " [ 10  18  37  77  54  14 772   4  13   1]\n",
            " [ 33   3  28  67  42  46   0 772   3   6]\n",
            " [ 83  19   9   7   3   2   2   4 867   4]\n",
            " [ 37  97   8   9   0   7   3   5  54 780]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: Loss: 0.8401, Train Accuracy: 71.19%\n",
            "Test Accuracy: 75.80%\n",
            "Confusion Matrix (Epoch 5):\n",
            "[[752  28  70  10  19   3  13  10  76  19]\n",
            " [  8 939   6  10   0   2   0   1  18  16]\n",
            " [ 64   6 672  36  60  40  85  22  15   0]\n",
            " [ 26   5 114 619  42 114  44  19  16   1]\n",
            " [ 14   2  79  41 725  30  50  47  12   0]\n",
            " [ 15   1  90 146  45 658  12  29   4   0]\n",
            " [  6   7  69  67  20  15 804   2  10   0]\n",
            " [ 18   7  51  35  25  41   4 813   2   4]\n",
            " [ 41  45  11  11   3   4   3   3 870   9]\n",
            " [ 26 155  13  16   1  11   5  13  32 728]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6: Loss: 0.7158, Train Accuracy: 75.35%\n",
            "Test Accuracy: 79.91%\n",
            "Confusion Matrix (Epoch 6):\n",
            "[[876  10  43   8   5   0   3   3  37  15]\n",
            " [ 16 917   6   2   1   1   3   1  19  34]\n",
            " [ 44   2 833  35  28   6  27  17   3   5]\n",
            " [ 34   7  78 687  39  48  71  19   7  10]\n",
            " [ 14   1 123  29 740   7  35  42   7   2]\n",
            " [ 19   1 119 218  40 512  38  48   1   4]\n",
            " [  9   6  50  31  11   2 887   3   1   0]\n",
            " [ 28   2  39  40  29  12   6 828   3  13]\n",
            " [ 57  15  15   9   1   0   5   2 887   9]\n",
            " [ 54  85   5   6   0   1   3   3  19 824]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7: Loss: 0.6483, Train Accuracy: 77.52%\n",
            "Test Accuracy: 80.56%\n",
            "Confusion Matrix (Epoch 7):\n",
            "[[826  10  37  15   5   2   4   0  92   9]\n",
            " [  7 913   8   5   1   8   5   0  38  15]\n",
            " [ 47   0 782  41  48  23  39  11   7   2]\n",
            " [ 20   1  81 686  30 106  50  14  11   1]\n",
            " [  9   0  84  44 780  25  40  10   8   0]\n",
            " [  7   0  67 141  34 713  15  16   7   0]\n",
            " [  4   3  35  35   3  13 897   4   6   0]\n",
            " [ 24   4  40  42  59  51   4 769   3   4]\n",
            " [ 19  13  19  13   3   2   0   0 929   2]\n",
            " [ 40 100  10   9   0  13   8   1  58 761]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8: Loss: 0.6223, Train Accuracy: 78.48%\n",
            "Test Accuracy: 80.15%\n",
            "Confusion Matrix (Epoch 8):\n",
            "[[862  20  15  21  15   0   6   6  27  28]\n",
            " [ 10 894   2   8   9   2   9   3   9  54]\n",
            " [ 64   2 606  69 101  49  81  10   5  13]\n",
            " [ 15   2  20 710  43 116  62   8   9  15]\n",
            " [  8   0  23  56 845   9  38  13   6   2]\n",
            " [  6   1  17 166  56 681  35  25   3  10]\n",
            " [  3   2   6  52  14   4 915   0   2   2]\n",
            " [ 10   1  14  59  69  35  11 780   1  20]\n",
            " [ 46  44   6  17   3   1   6   1 858  18]\n",
            " [ 17  75   1   8   6   5   7   4  13 864]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9: Loss: 0.6860, Train Accuracy: 76.52%\n",
            "Test Accuracy: 79.24%\n",
            "Confusion Matrix (Epoch 9):\n",
            "[[824  21  28   9   9   1   5   0  83  20]\n",
            " [  5 941   1   3   2   0   0   0  19  29]\n",
            " [ 58   7 660  53  98  24  62  12  22   4]\n",
            " [ 32  14  50 627  62  72  88  14  24  17]\n",
            " [ 26   2  29  22 835   7  31  33  13   2]\n",
            " [ 16   4  44 174  51 620  46  25  11   9]\n",
            " [  9   6  18  31  16   4 903   2  10   1]\n",
            " [ 28   2  30  55  46  23  10 792   7   7]\n",
            " [ 28  25   2   7   3   0   4   0 925   6]\n",
            " [ 29 125   3   3   0   0   6   2  35 797]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10: Loss: 0.6041, Train Accuracy: 79.01%\n",
            "Test Accuracy: 82.42%\n",
            "Confusion Matrix (Epoch 10):\n",
            "[[865   7  33   4  14   1   2   5  38  31]\n",
            " [  4 869   7   3   3   5   2   1  27  79]\n",
            " [ 39   2 796  36  42  39  19  17   8   2]\n",
            " [ 22   4  60 672  46  98  32  44  11  11]\n",
            " [  4   1  72  22 780  20  17  72   8   4]\n",
            " [  8   0  37 153  29 701   9  53   4   6]\n",
            " [ 12   2  42  41  19  14 857   7   2   4]\n",
            " [ 13   0  19  28  18  19   0 895   1   7]\n",
            " [ 39   9  10   5   3   1   3   1 920   9]\n",
            " [ 22  30   6   8   2   2   2   3  38 887]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11: Loss: 0.4862, Train Accuracy: 83.08%\n",
            "Test Accuracy: 85.31%\n",
            "Confusion Matrix (Epoch 11):\n",
            "[[881  12  26   6  10   0   5   2  42  16]\n",
            " [  6 937   2   3   0   2   0   1  12  37]\n",
            " [ 43   1 791  29  49  32  34  10   7   4]\n",
            " [ 20   6  46 668  37 143  36  29   8   7]\n",
            " [  6   1  33  23 845  23  28  33   6   2]\n",
            " [  6   0  28 108  27 784  12  28   5   2]\n",
            " [  6   3  21  32  10   9 913   2   4   0]\n",
            " [ 15   0  15  24  21  32   2 882   2   7]\n",
            " [ 28  14   3   5   4   2   0   0 935   9]\n",
            " [ 20  51   3   4   0   2   2   2  21 895]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12: Loss: 0.4437, Train Accuracy: 84.48%\n",
            "Test Accuracy: 85.57%\n",
            "Confusion Matrix (Epoch 12):\n",
            "[[886  10  26   5   6   1   3   5  43  15]\n",
            " [  6 938   4   4   1   1   1   1  11  33]\n",
            " [ 40   1 798  33  47  31  31  12   6   1]\n",
            " [ 18   5  42 714  37 115  25  28  10   6]\n",
            " [  7   1  36  30 857  18  18  26   5   2]\n",
            " [  4   0  28 141  29 757   7  29   5   0]\n",
            " [  5   3  24  41  11   7 903   2   4   0]\n",
            " [ 11   0  11  26  28  31   0 886   2   5]\n",
            " [ 36  12   3   4   5   1   0   1 931   7]\n",
            " [ 21  54   2   6   0   4   3   4  19 887]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13: Loss: 0.4277, Train Accuracy: 85.08%\n",
            "Test Accuracy: 85.95%\n",
            "Confusion Matrix (Epoch 13):\n",
            "[[880  10  26   8   7   1   4   1  48  15]\n",
            " [  6 934   3   3   0   2   1   0  15  36]\n",
            " [ 38   1 827  27  40  24  23  12   7   1]\n",
            " [ 19   6  43 709  31 126  28  25   8   5]\n",
            " [  7   1  45  27 850  17  25  21   6   1]\n",
            " [  5   0  35 122  27 771  10  24   5   1]\n",
            " [  5   3  27  32  11   7 908   1   5   1]\n",
            " [ 14   0  15  26  21  27   1 890   0   6]\n",
            " [ 29  11   3   5   5   2   0   1 934  10]\n",
            " [ 22  47   3   6   0   4   2   1  23 892]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14: Loss: 0.4150, Train Accuracy: 85.58%\n",
            "Test Accuracy: 86.16%\n",
            "Confusion Matrix (Epoch 14):\n",
            "[[900   9  23   6   9   1   3   3  33  13]\n",
            " [  6 939   1   5   0   3   1   1  15  29]\n",
            " [ 34   2 825  32  41  26  20  13   6   1]\n",
            " [ 17   3  40 719  34 127  26  20   8   6]\n",
            " [  7   1  40  32 848  20  20  28   4   0]\n",
            " [  4   0  34 118  24 782  11  23   3   1]\n",
            " [  5   3  30  36  12   7 897   4   5   1]\n",
            " [ 11   0  12  29  18  35   1 887   2   5]\n",
            " [ 34  10   5   6   3   3   0   0 929  10]\n",
            " [ 21  49   3   6   0   4   2   2  23 890]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15: Loss: 0.3954, Train Accuracy: 86.19%\n",
            "Test Accuracy: 86.21%\n",
            "Confusion Matrix (Epoch 15):\n",
            "[[904   9  19  11   6   0   3   4  30  14]\n",
            " [  6 944   1   5   1   2   1   0  12  28]\n",
            " [ 42   2 815  34  41  29  17  15   4   1]\n",
            " [ 13   4  39 740  29 116  22  25   9   3]\n",
            " [  5   1  35  38 843  21  22  30   5   0]\n",
            " [  5   0  23 131  17 781  13  27   3   0]\n",
            " [  6   3  28  46   9   9 889   4   4   2]\n",
            " [ 13   0  12  25  14  34   2 894   2   4]\n",
            " [ 38  12   5   7   4   2   0   0 925   7]\n",
            " [ 23  49   2   7   0   3   3   4  23 886]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16: Loss: 0.3821, Train Accuracy: 86.52%\n",
            "Test Accuracy: 86.37%\n",
            "Confusion Matrix (Epoch 16):\n",
            "[[887   9  26   7  10   1   4   4  40  12]\n",
            " [  5 943   2   5   1   3   2   0  15  24]\n",
            " [ 30   1 823  30  47  29  22  12   5   1]\n",
            " [ 15   4  37 706  37 137  28  24   7   5]\n",
            " [  4   1  32  27 866  19  20  26   5   0]\n",
            " [  4   0  21 114  25 799  11  21   4   1]\n",
            " [  5   3  24  30   9   8 913   3   3   2]\n",
            " [ 11   0   9  24  28  31   1 891   1   4]\n",
            " [ 32  11   6   7   3   4   0   0 931   6]\n",
            " [ 20  62   3   6   1   4   1   2  23 878]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17: Loss: 0.3817, Train Accuracy: 86.66%\n",
            "Test Accuracy: 86.57%\n",
            "Confusion Matrix (Epoch 17):\n",
            "[[908   9  17  10   5   0   3   2  31  15]\n",
            " [  6 949   1   5   0   4   0   0  11  24]\n",
            " [ 35   1 827  33  36  31  17  14   5   1]\n",
            " [ 15   3  40 711  30 136  27  26   7   5]\n",
            " [  6   1  39  35 849  18  20  26   6   0]\n",
            " [  5   0  23 101  21 813  10  23   2   2]\n",
            " [  5   2  31  39   7   6 900   3   4   3]\n",
            " [ 11   0  12  18  24  33   1 896   1   4]\n",
            " [ 37  14   5   5   3   3   0   0 921  12]\n",
            " [ 24  61   2   5   1   4   2   2  16 883]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18: Loss: 0.3728, Train Accuracy: 86.87%\n",
            "Test Accuracy: 86.79%\n",
            "Confusion Matrix (Epoch 18):\n",
            "[[905   9  22   6  11   0   4   3  25  15]\n",
            " [  7 950   1   6   0   0   0   0  11  25]\n",
            " [ 29   2 846  33  39  16  16  13   3   3]\n",
            " [ 15   4  37 747  35  97  26  27   6   6]\n",
            " [  5   1  43  28 860  13  19  27   4   0]\n",
            " [  5   0  27 136  25 766  12  25   3   1]\n",
            " [  5   4  31  42   9   6 893   3   4   3]\n",
            " [ 11   0  13  20  22  21   2 906   1   4]\n",
            " [ 39  12   5   6   4   4   0   0 922   8]\n",
            " [ 19  63   3   3   0   4   2   4  18 884]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19: Loss: 0.3555, Train Accuracy: 87.52%\n",
            "Test Accuracy: 86.42%\n",
            "Confusion Matrix (Epoch 19):\n",
            "[[892  10  23  11   7   1   3   2  36  15]\n",
            " [  5 936   1   3   0   5   3   0  15  32]\n",
            " [ 31   1 832  30  40  29  15  14   5   3]\n",
            " [ 15   3  40 719  30 150  18  18   5   2]\n",
            " [  6   1  38  30 856  23  14  26   6   0]\n",
            " [  4   0  25 109  20 806   7  26   1   2]\n",
            " [  5   2  27  51  12  11 883   5   1   3]\n",
            " [ 10   0  11  21  23  39   2 890   0   4]\n",
            " [ 28  10   7   7   4   3   0   0 932   9]\n",
            " [ 16  48   3   9   0   4   2   1  21 896]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20: Loss: 0.3477, Train Accuracy: 87.87%\n",
            "Test Accuracy: 86.60%\n",
            "Confusion Matrix (Epoch 20):\n",
            "[[897  10  22  11   9   1   3   2  30  15]\n",
            " [  2 949   1   5   0   4   1   0  13  25]\n",
            " [ 33   2 847  29  35  25  12  10   5   2]\n",
            " [ 15   3  38 725  33 127  31  18   5   5]\n",
            " [  5   1  43  28 850  18  20  30   5   0]\n",
            " [  6   0  25 125  20 783  13  22   5   1]\n",
            " [  5   2  28  37   9   7 904   3   2   3]\n",
            " [  9   0  14  22  24  31   1 893   1   5]\n",
            " [ 34  17   7   6   4   1   0   0 923   8]\n",
            " [ 23  59   2   3   0   4   2   1  17 889]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21: Loss: 0.3323, Train Accuracy: 88.32%\n",
            "Test Accuracy: 86.95%\n",
            "Confusion Matrix (Epoch 21):\n",
            "[[915   7  19   6   8   1   3   2  26  13]\n",
            " [  5 945   2   4   0   4   1   0  14  25]\n",
            " [ 33   1 847  30  39  21  14   9   5   1]\n",
            " [ 16   3  37 736  33 119  30  18   5   3]\n",
            " [  5   1  39  28 863  18  20  21   5   0]\n",
            " [  5   0  24 127  23 785  12  19   4   1]\n",
            " [  5   2  25  39  12   7 902   3   2   3]\n",
            " [ 12   0  12  22  26  33   2 888   1   4]\n",
            " [ 40  14   5   5   4   2   0   0 922   8]\n",
            " [ 24  54   3   4   0   4   2   1  16 892]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22: Loss: 0.3222, Train Accuracy: 88.70%\n",
            "Test Accuracy: 86.93%\n",
            "Confusion Matrix (Epoch 22):\n",
            "[[912   7  19   6   6   1   3   2  31  13]\n",
            " [  5 944   2   4   0   4   1   0  15  25]\n",
            " [ 36   1 847  29  35  24  14   8   5   1]\n",
            " [ 15   3  40 729  30 131  26  17   6   3]\n",
            " [  6   1  40  27 857  20  20  24   5   0]\n",
            " [  6   0  23 115  19 802  11  20   3   1]\n",
            " [  5   2  29  37  11   9 898   4   2   3]\n",
            " [ 13   0  12  23  23  36   2 886   1   4]\n",
            " [ 36  14   5   7   3   3   0   0 925   7]\n",
            " [ 24  50   3   5   0   3   2   2  18 893]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23: Loss: 0.3216, Train Accuracy: 88.65%\n",
            "Test Accuracy: 87.07%\n",
            "Confusion Matrix (Epoch 23):\n",
            "[[910   8  23   8   6   1   3   3  26  12]\n",
            " [  5 945   2   5   0   3   2   0  12  26]\n",
            " [ 34   1 846  34  36  20  15   9   4   1]\n",
            " [ 15   2  36 756  33 110  27  14   4   3]\n",
            " [  5   1  40  32 866  17  18  16   5   0]\n",
            " [  5   0  22 134  20 782  13  20   2   2]\n",
            " [  5   2  22  41  10   5 912   1   0   2]\n",
            " [ 11   0  14  26  25  36   2 882   0   4]\n",
            " [ 39  14   8   9   4   3   0   0 915   8]\n",
            " [ 24  53   3   8   0   3   2   1  13 893]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24: Loss: 0.3258, Train Accuracy: 88.44%\n",
            "Test Accuracy: 87.06%\n",
            "Confusion Matrix (Epoch 24):\n",
            "[[902   8  23   7   7   1   4   3  32  13]\n",
            " [  4 950   1   4   0   4   1   0  12  24]\n",
            " [ 33   2 842  30  38  22  14  13   5   1]\n",
            " [ 13   3  38 728  34 132  26  17   6   3]\n",
            " [  6   1  41  29 857  20  16  25   5   0]\n",
            " [  5   0  21 110  19 809  12  20   2   2]\n",
            " [  5   3  26  36  12   7 905   3   1   2]\n",
            " [ 11   0  11  20  25  33   2 894   0   4]\n",
            " [ 33  15   7   6   3   3   0   0 926   7]\n",
            " [ 23  54   3   4   0   3   2   2  16 893]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25: Loss: 0.3193, Train Accuracy: 88.89%\n",
            "Test Accuracy: 86.98%\n",
            "Confusion Matrix (Epoch 25):\n",
            "[[915   8  17   7   6   0   4   2  29  12]\n",
            " [  6 944   0   4   0   4   1   0  14  27]\n",
            " [ 40   2 834  35  36  23  13  11   5   1]\n",
            " [ 15   3  39 745  27 121  24  18   5   3]\n",
            " [  6   1  38  29 859  19  16  26   6   0]\n",
            " [  6   0  20 127  20 790  11  21   4   1]\n",
            " [  5   2  29  38  12   7 900   2   2   3]\n",
            " [ 15   0  12  21  25  33   2 888   0   4]\n",
            " [ 33  14   4   6   3   3   0   0 930   7]\n",
            " [ 26  53   2   4   0   3   2   1  16 893]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26: Loss: 0.3192, Train Accuracy: 88.85%\n",
            "Test Accuracy: 87.11%\n",
            "Confusion Matrix (Epoch 26):\n",
            "[[906   8  20   9   8   0   4   3  30  12]\n",
            " [  6 942   1   4   0   3   1   1  14  28]\n",
            " [ 34   1 839  31  40  21  14  14   5   1]\n",
            " [ 14   3  38 739  34 120  25  18   5   4]\n",
            " [  5   1  36  29 865  19  16  24   5   0]\n",
            " [  5   0  21 117  21 802  10  20   3   1]\n",
            " [  5   2  26  40  13   7 901   2   1   3]\n",
            " [ 11   0  10  17  27  32   2 896   0   5]\n",
            " [ 37  13   5   7   3   4   0   0 923   8]\n",
            " [ 24  46   3   6   0   3   2   2  16 898]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-c24ef4166f49>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1457\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1459\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1418\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1419\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1421\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1249\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1251\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    120\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;31m# unserialize the data after having released the lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mqsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/multiprocessing/reductions.py\u001b[0m in \u001b[0;36mrebuild_storage_fd\u001b[0;34m(cls, df, size)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrebuild_storage_fd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m     \u001b[0mfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage_from_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/multiprocessing/resource_sharer.py\u001b[0m in \u001b[0;36mdetach\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;34m'''Get the fd.  This should only be called once.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0m_resource_sharer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/multiprocessing/resource_sharer.py\u001b[0m in \u001b[0;36mget_connection\u001b[0;34m(ident)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconnection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mClient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mident\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/multiprocessing/connection.py\u001b[0m in \u001b[0;36mClient\u001b[0;34m(address, family, authkey)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mauthkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m         \u001b[0manswer_challenge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m         \u001b[0mdeliver_challenge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/multiprocessing/connection.py\u001b[0m in \u001b[0;36manswer_challenge\u001b[0;34m(connection, authkey)\u001b[0m\n\u001b[1;32m    772\u001b[0m     \u001b[0mdigest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhmac\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauthkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'md5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdigest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m     \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdigest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 774\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m        \u001b[0;31m# reject large message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    775\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mWELCOME\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mAuthenticationError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'digest sent was rejected'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"negative maxlength\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bad_message_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(acc_list)\n",
        "plt.title('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.xticks(np.arange(0,50,10))\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MbirHkAvOW83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(train_acc_list)\n",
        "plt.title('Training Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.xticks(np.arange(0,50,10))\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xvT_gz6HOcRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(loss_list)\n",
        "plt.title('Cross Entropy Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.xticks(np.arange(0,50,10))\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2scMS8LfOgkl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}